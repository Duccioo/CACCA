# ğŸ’©âœ¨ C.A.C.C.A âœ¨ğŸ’©

**C**alamita's **A**lexia with **C**ool **C**onditional **A**utoencoder

---

## ğŸš§âš ï¸ Disclaimer âš ï¸ğŸš§
This repository is under active development! ğŸ”¨ğŸ‘·â€â™€ï¸ Some features might change over time, including the project name! ğŸ’¡âœ¨ğŸ¨ Stay tuned for updates! ğŸš€ğŸ‰

---

## ğŸ“–ğŸ”¬ Description 

CACCA is a **Conditional Autoencoder (CAE)** ğŸ¤– and **Conditional Variational Autoencoder (CVAE)** ğŸ§  project designed to learn powerful latent representations (embeddings) of chemical structures ğŸ§ª represented as SMILES strings from the ZINC dataset! ğŸ’ŠğŸ“Š

ğŸ¯ğŸŒŸ **Main Goal**: Create a rich and structured latent space where molecules ğŸ§¬ are organized not only by their chemical structure but also by their key molecular properties (molecular weight âš–ï¸, logP ğŸ’§, H-bond donors/acceptors ğŸ”—, TPSA ğŸˆ)!

### ğŸ”¬âœ¨ Key Features ğŸŒˆğŸš€

- ğŸ¨ **Automatic Preprocessing**: SMILES canonicalization and calculation of 5 molecular properties ğŸ“
- ğŸ¤– **Supported Models**: CAE and CVAE with BiLSTM architecture ğŸ§ ğŸ’ª
- ğŸ‹ï¸ **Flexible Training**: Multi-GPU support, automatic checkpoints, and detailed metrics ğŸ“Šâœ…
- ğŸ¨ **Conditional Generation**: Generate new molecules by specifying target properties! ğŸ¯ğŸ§ª
- ğŸ“ˆ **Advanced Analysis**: Evaluate embeddings with PCA, UMAP, and clustering metrics ğŸ”ğŸ“‰

---

## ğŸš€ğŸ’« Installation 

### ğŸ“‹âœ… Requirements
- ğŸ Python 3.8+
- ğŸ® CUDA (optional, for GPU training) âš¡

### ğŸ› ï¸âš™ï¸ Setup

1. ğŸ“¥ **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd CACCA
   ```

2. ğŸ **Create a virtual environment**:
   ```bash
   python -m venv venv
   ```

3. âœ¨ **Activate it**:
   - On Windows ğŸªŸğŸ’»:
     ```bash
     .\venv\Scripts\activate
     ```
   - On macOS/Linux ğŸ§ğŸ:
     ```bash
     source venv/bin/activate
     ```

4. ğŸ“¦ğŸ”§ **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ’»ğŸ¯ Usage 

### ğŸ“ŠğŸ§¹ Step 1: Data Preprocessing 

The preprocessing step canonicalizes SMILES ğŸ§ª, calculates molecular properties ğŸ”¬, and applies scaling (Z-score or Min-Max) ğŸ“!

**ğŸ¬ Basic command**:
```bash
python src/preprocess_data.py \
    --input-file dataset/ZINC_base/smiles.txt \
    --scale zscore
```

**âš™ï¸ğŸ“ Available parameters**:
- ğŸ“‚ `--input-file`: Path to file containing SMILES (`.txt` or `.csv`)
- ğŸ“‹ `--smiles-column`: SMILES column name (for CSV files only)
- ğŸ“ `--scale`: Scaling method (`zscore` or `minmax` or `None`)
- ğŸ’¾ `--output-file`: Output file path (optional)

**âœ¨ğŸ“¤ Output**: CSV file with canonical SMILES and 5 scaled properties:
- âš–ï¸ Exact Molecular Weight (ExactMolWt)
- ğŸ’§ logP (partition coefficient)
- ğŸ”— H-bond Donors (HBD)
- ğŸ¯ H-bond Acceptors (HBA)
- ğŸˆ Topological Polar Surface Area (TPSA)

**ğŸ¨ Example with CSV**:
```bash
python src/preprocess_data.py \
    --input-file assets/mol_test.csv \
    --smiles-column SMILES \
    --scale zscore
```

---

### ğŸ§ ğŸ’ª Step 2: Model Training 

Train a Conditional Autoencoder or CVAE on preprocessed SMILES! ğŸš€ğŸ“

**ğŸ¬âš¡ Basic command**:
```bash
python src/trainining_cae.py \
    --model_type CVAE \
    --prop_file dataset/ZINC_with_drugs/smiles_preprocessed_scale-zscore.csv \
    --model_dir saved_models/my_model \
    --num_epochs 100 \
    --batch_size 256 \
    --lr 3e-4
```

**âš™ï¸ğŸ›ï¸ Main parameters**:

*ğŸ—ï¸ğŸ¤– Model Architecture*:
- ğŸ­ `--model_type`: Model type (`CAE` or `CVAE`)
- ğŸ“¦ `--emb_size`: Embedding dimension (default: 256)
- ğŸŒŒ `--latent_size`: Latent space dimension (default: 200)
- ğŸ§© `--hidden_size`: RNN unit size (default: 512)
- ğŸ”¢ `--n_rnn_layer`: Number of RNN layers (default: 3)

*ğŸ‹ï¸ğŸ“š Training*:
- ğŸ“‚ `--prop_file`: Path to preprocessed file
- ğŸ”„ `--num_epochs`: Number of epochs
- ğŸ“¦ `--batch_size`: Batch size
- ğŸ“ˆ `--lr`: Learning rate
- âš–ï¸ `--weight_decay`: Weight decay for optimizer
- ğŸ“Š `--training_percent`: Training data percentage (default: 0.75)
- ğŸ“ `--max_seq_length`: Maximum SMILES sequence length (default: 120)
- ğŸ² `--seed`: Random seed for reproducibility

*ğŸ’¾ğŸ“ Output*:
- ğŸ—‚ï¸ `--model_dir`: Directory to save models and checkpoints

**âœ¨ğŸ“¤ Training outputs**:
- ğŸ“– `vocab.pkl`: SMILES character vocabulary
- âš™ï¸ `args.json`: Training parameters
- ğŸ’¾ `model_X.pt`: Model checkpoint at epoch X
- ğŸ† `model_X_best.pt`: Best model based on validation loss

**ğŸ¯ğŸ”¥ Complete training example**:
```bash
python src/trainining_cae.py \
    --model_type CVAE \
    --prop_file dataset/ZINC_with_drugs/smiles_preprocessed_scale-zscore.csv \
    --model_dir saved_models/model_CVAE_v5.1 \
    --num_epochs 150 \
    --batch_size 128 \
    --lr 3e-4 \
    --latent_size 200 \
    --emb_size 256 \
    --hidden_size 512 \
    --seed 69
```

---

### ğŸ¨âœ¨ Step 3: Generate New Molecules 

Generate brand new molecules ğŸ§ªğŸ’« by specifying target molecular properties! ğŸ¯ğŸ”¬

**ğŸ¬ğŸš€ Basic command**:
```bash
python src/generate_new.py \
    --save_dir saved_models/model_CVAE_v5.1 \
    --num_samples 50 \
    --logP_min 0 \
    --logP_max 3
```

**âš™ï¸ğŸ“ Available parameters**:
- ğŸ—‚ï¸ `--save_dir`: Directory of the trained model
- ğŸ”¢ `--num_samples`: Number of molecules to generate
- ğŸŒŒ `--latent_size`: Latent space dimension (must match the model)
- ğŸ“ `--seq_length`: Maximum generated sequence length (default: 120)
- ğŸ’¾ `--output_file`: File to save generated SMILES (optional)

*ğŸ¯ğŸ”¬ Molecular property ranges*:
- ğŸ’§ `--logP_min`, `--logP_max`: Range for logP
- âš–ï¸ `--MolWt_min`, `--MolWt_max`: Range for molecular weight
- ğŸ”— `--HBD_min`, `--HBD_max`: Range for H donors
- ğŸ¯ `--HBA_min`, `--HBA_max`: Range for H acceptors
- ğŸˆ `--TPSA_min`, `--TPSA_max`: Range for TPSA

**ğŸ¨ğŸ”¥ Targeted generation example**:
```bash
python src/generate_new.py \
    --save_dir saved_models/model_CVAE_v5.1 \
    --num_samples 100 \
    --logP_min 2.0 \
    --logP_max 4.0 \
    --MolWt_min 200 \
    --MolWt_max 500 \
    --output_file assets/generated.smi
```

---

### ğŸ“ˆğŸ” Step 4: Embeddings Analysis 

Evaluate the quality of embeddings ğŸ§ âœ¨ generated by the model using various dimensionality reduction techniques and metrics! ğŸ“ŠğŸ¯

**ğŸ¬ğŸ’« Basic command**:
```bash
python src/metric_final.py
```

This script does the following magic ğŸª„:
1. ğŸ“¥ Loads a trained model and a test molecule set
2. ğŸŒˆ Generates embeddings using different methods:
   - ğŸ¤– **CAE**: Embeddings from autoencoder latent space
   - ğŸ“‰ **PCA**: Dimensionality reduction on molecular descriptors
   - ğŸ—ºï¸ **UMAP**: Dimensionality reduction on descriptors, fingerprints, or CAE embeddings
3. ğŸ“Š Calculates evaluation metrics:
   - ğŸ¯ **Enrichment Factor (EF@k)**: Ability to retrieve similar molecules
   - ğŸ’¯ **PP-hit@k**: Proportion of positive molecules among k neighbors
   - ğŸŒŸ **Silhouette Score**: Clustering quality

**âœ¨ğŸ“¤ Output**:
- ğŸ“ Directory `analysis_results_nX/`:
  - ğŸ—‚ï¸ `embeddings_METHOD.csv`: Embeddings for each method
  - ğŸ“ `distances_METHOD.csv`: Distances from reference polymer
  - ğŸ“‹ `metrics_summary_report.csv`: Summary report of all metrics

**ğŸ“âœï¸ Note**: Modify the file to specify:
- ğŸ—‚ï¸ Path to trained model
- ğŸ“‚ CSV file with test molecules
- ğŸ¯ Reference polymer name
- ğŸ’¾ Output directory

---

### ğŸ”§ğŸ› ï¸ Additional Scripts 

#### ğŸ¨ `generatore2.py`
Alternative molecule generator ğŸ§ªâœ¨ with similar interface to `generate_new.py`!

#### ğŸ“Š `prop_smiles.py`
Utility to calculate and visualize ğŸ”¬ğŸ‘€ molecular properties from SMILES!

```bash
python src/prop_smiles.py
```

---

## ğŸ“ğŸ—‚ï¸ Project Structure 

```
CACCA/ ğŸ 
â”œâ”€â”€ src/ ğŸ’»
â”‚   â”œâ”€â”€ preprocess_data.py      # ğŸ§¹ SMILES preprocessing
â”‚   â”œâ”€â”€ trainining_cae.py       # ğŸ‹ï¸ Model training
â”‚   â”œâ”€â”€ generate_new.py         # ğŸ¨ Molecule generation
â”‚   â”œâ”€â”€ generatore2.py          # ğŸª Alternative generator
â”‚   â”œâ”€â”€ metric_final.py         # ğŸ“Š Analysis and metrics
â”‚   â”œâ”€â”€ prop_smiles.py          # ğŸ”¬ Property calculation
â”‚   â”œâ”€â”€ model/ ğŸ¤–
â”‚   â”‚   â”œâ”€â”€ CAE.py             # ğŸ§  CAE and CVAE architectures
â”‚   â”‚   â””â”€â”€ ... âœ¨
â”‚   â””â”€â”€ utils/ ğŸ› ï¸
â”‚       â”œâ”€â”€ data_utils.py      # ğŸ“¦ Data management utilities
â”‚       â”œâ”€â”€ utils.py           # ğŸ”§ Helper functions
â”‚       â””â”€â”€ ... ğŸ’«
â”œâ”€â”€ dataset/ ğŸ“š
â”‚   â”œâ”€â”€ ZINC_base/             # ğŸ’Š Base ZINC dataset
â”‚   â””â”€â”€ ZINC_with_drugs/       # ğŸ’‰ ZINC + drugs dataset
â”œâ”€â”€ saved_models/ ğŸ’¾            # ğŸ† Trained models
â”œâ”€â”€ assets/ ğŸ                  # ğŸ“„ Test files and resources
â”œâ”€â”€ analysis_results_nX/ ğŸ“ˆ    # ğŸ“Š Analysis results
â”œâ”€â”€ requirements.txt ğŸ“‹         # ğŸ Python dependencies
â””â”€â”€ README.md ğŸ“–                # ğŸ“š This documentation
```

---

## ğŸ”¬ğŸ§ª Technical Details 

### ğŸ—ï¸ğŸ¤– Model Architecture 

**ğŸ¯ Conditional Autoencoder (CAE)**:
- ğŸ§  **Encoder**: BiLSTM that processes SMILES + molecular properties ğŸ”—
- ğŸŒŒ **Latent Space**: Compact representation of the molecule âœ¨
- ğŸ¨ **Decoder**: Autoregressive LSTM that generates SMILES token-by-token ğŸ“
- ğŸ”® **Property Predictor**: MLP that predicts properties from latent vector ğŸ¯

**âœ¨ Conditional Variational Autoencoder (CVAE)**:
- ğŸ² Like CAE, but with sampling from latent space (mean + log_sigma) ğŸŒŸ
- ğŸ“‰ Additional loss: KL divergence for regularization âš–ï¸

### ğŸ§¬ğŸ’Š Molecular Properties Used 

1. âš–ï¸ **ExactMolWt**: Exact molecular weight
2. ğŸ’§ **MolLogP**: Octanol/water partition coefficient (lipophilicity)
3. ğŸ”— **CalcNumHBD**: Number of hydrogen bond donors
4. ğŸ¯ **CalcNumHBA**: Number of hydrogen bond acceptors
5. ğŸˆ **CalcTPSA**: Topological polar surface area

---

## ğŸ“ŠğŸ’Š Dataset 

The project uses the ZINC dataset ğŸ›ï¸, a free library of commercially available chemical compounds! ğŸ§ªâœ¨ The file is automatically downloaded ğŸ“¥ during preprocessing if not present! ğŸ‰

**âœ¨ğŸ¨ To add custom molecules**:
1. ğŸ“ Add SMILES to the file `dataset/ZINC_base/smiles.txt` (one per line)
2. ğŸ“‹ Or create a CSV with a SMILES column
3. ğŸš€ Run preprocessing as indicated above!

---

## ğŸ¯ğŸ”¥ Complete Workflow 

```bash
# 1. ğŸ§¹âœ¨ Preprocessing
python src/preprocess_data.py \
    --input-file dataset/ZINC_base/smiles.txt \
    --scale zscore

# 2. ğŸ‹ï¸ğŸ’ª Training
python src/trainining_cae.py \
    --model_type CVAE \
    --prop_file dataset/ZINC_base/smiles_preprocessed_scale-zscore.csv \
    --model_dir saved_models/my_cvae \
    --num_epochs 100

# 3. ğŸ¨ğŸ§ª Generation
python src/generate_new.py \
    --save_dir saved_models/my_cvae \
    --num_samples 50 \
    --logP_min 1.0 \
    --logP_max 3.0 \
    --output_file generated_molecules.smi

# 4. ğŸ“ŠğŸ” Analysis (after configuring metric_final.py)
python src/metric_final.py
```

---

## ğŸ¤ğŸ’– Contributions 

Contributions, suggestions, and feedback are super welcome! ğŸ‰âœ¨ Feel free to open issues ğŸ› or pull requests ğŸ”€! We love collaboration! ğŸ’ªğŸŒŸ

---

## ğŸ“âš–ï¸ License 

*Specify license here if applicable* ğŸ“œâœ¨

---

## ğŸ™ğŸŒŸ Acknowledgments 

- ğŸ§ª **RDKit**: For molecular property calculations! ğŸ”¬
- ğŸ’Š **ZINC Database**: For the amazing molecule dataset! ğŸ“Š
- ğŸ”¥ **PyTorch**: Deep learning framework extraordinaire! ğŸ§ 

---

## ğŸ®ğŸš€ Get Started! 

Ready to dive into molecular magic? ğŸ§™â€â™‚ï¸âœ¨ Follow the steps above and start creating amazing molecules! ğŸ§¬ğŸ’«

Got questions? ğŸ¤” Need help? ğŸ’¬ Don't hesitate to reach out! ğŸ“§

---

**Happy Molecular Hacking!** ğŸ’©ğŸ§¬ğŸ‰âœ¨ğŸ”¬ğŸ¯ğŸš€ğŸ’«ğŸŒŸğŸ¨ğŸ”¥ğŸ’ªğŸ§ªğŸ†

*Let's make some awesome molecules together!* ğŸ¤ğŸ’–ğŸ§¬
```

---

## ï¿½ Contributi

Contributi, suggerimenti e feedback sono benvenuti! Sentiti libero di aprire issue o pull request.

---


## ğŸ™ Riconoscimenti

- **RDKit**: Per il calcolo delle proprietÃ  molecolari
- **ZINC Database**: Per il dataset di molecole
- **PyTorch**: Framework per il deep learning

---

Happy Molecular Hacking! ğŸ’©ğŸ§¬
